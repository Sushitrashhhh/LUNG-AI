import torch
from PIL import Image
from torchvision import transforms
from architecture import ResNetLungCancer 

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

model = ResNetLungCancer(num_classes=4)
try:
    state = torch.load('Model/lung_cancer_detection_model.pth', map_location=device, weights_only=True)
except TypeError:
    state = torch.load('Model/lung_cancer_detection_model.pth', map_location=device)

if isinstance(state, dict) and 'state_dict' in state:
    state = state['state_dict']

model.load_state_dict(state)
model = model.to(device)
model.eval()

preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# image from local file
# Use an image from the processed dataset (generated by preprocess.py)
# Available example: Processed_Data/test/Large_cell_carcinoma/test_Large_cell_carcinoma_108.jpg
image_path = "Processed_Data/test/Large_cell_carcinoma/test_Large_cell_carcinoma_108.jpg"
image = Image.open(image_path).convert('RGB')

# preprocess the image
input_tensor = preprocess(image).unsqueeze(0).to(device)  # add batch dimension and move to device

# get model predictions
with torch.no_grad():
    output = model(input_tensor)

predicted_class = torch.argmax(output, dim=1).item()

class_names = ['Adenocarcinoma', 'Large_cell_carcinoma', 'Normal', 'Squamous_cell_carcinoma']

print(f"Predicted class: {class_names[predicted_class]}")